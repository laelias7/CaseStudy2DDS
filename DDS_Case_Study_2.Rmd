---
title: "DDS Case Study 2"
author: "Linda Eliasen"
date: "April 19, 2019"
output: html_document
---
*Personal SMU Repository: <https://github.com/laelias7/SMU-MSDS.git>*      
*Video Presentation: <https://youtu.be/U9z4nmIYnBE>*

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, tidy=TRUE)
```


```{r libraries, include=FALSE}
library(tidyverse)
library(knitr)
library(dplyr)
library(magrittr)  
library(ggplot2)
library(kableExtra)
library(pROC)
library(ggcorrplot)
library(corrplot)
library(fastDummies)
library(alluvial)
library(caret)
library(randomForest)
library(RColorBrewer)
library(rpart)
library(class)
library(MASS)
library(knitr)
library(forecast)
library(car)
```
###Frito-Lay High Performer Turnover

DDSAnalytics was retained by Frito-Lay, a division of PepsiCo, to conduct an analysis into the underlying factors of regrettable turnover among their high performing employees in the Human Resources (HR), Research and Development (R&D) and Sales Functions.  <br>
<br>
The business impact of regrettable turnover is enormous. Each employee departure costs about one-third of that worker's annual earnings - - 33% in hard costs (such as recruiting, background checks, drug screens and temp workers) and 67% in soft costs (such as reduced productivity, interview time and lost knowledge).  Turnover not only creates loss of critical knowledge but can also impact the organization's talent pipeline and create a talent shortage.  
<br>
The analysis was conducted on 870 employees from these departments.  The data includes information in the following areas:  compensation, job role, education and company training, satisfaction scores, performance, personal attributes and other HR related items.
<br>
<br>

####Data Manipulation <br>
<br>

In order to obtain more focused results, the data was manipulated as follows:
<br>
<br>
Engineered Fields<br>

* Age Cat: Grouping of EEs by Age Category. <25, 25-30, 30-35, 35-40, 40-45, 45-50, 50+
* Educ_Field:  Combined Field:  Education + Education Field
* EE Satisfaction:  Avg of satisfaction scores per employee (Environment, Job Involvement, Job, Relationship, Work Life Balance)
* Other Company Experience:  Yes / No Classifier. Yes if Number Companies Worked -1 >0
* Prior Experience Years: Total Working Years - Years at Company
* Service Cat: Grouping of EEs by Company length of service 0-1, 1-3, 3-5, 5-8, 8-10, 10+
* Promo Last 3:  Yes/No Classifier if employee was promoted within the last 3 years
<br>
<br>

Trimming the data<br>
<br>
The following variables were removed from the datasets as they were either identifiers, non-unique across observations, the same as other variables (expressed differently), or included in the engineered variables:<br>

* ID, Employee Number, Rand
* Over18
* Standard Hours
* Employee Count
* Monthly Rate, Daily Rate, Hourly Rate
* Age
* Education, Education Field, 
* Environment Satisfaction, Job Involvement, Job Satisfaction, Relationship Satisfaction, Work Life Balance
* Total Working Years, Years at Company

```{r}
fp <- read.csv("CS2_data_comb.csv", header=T,na.strings=c(""))

fp = fp[ , !(names(fp) %in% c('ID','Over18', 'StandardHours', 'EmployeeCount',  'EmployeeNumber','Rand',
                              'MonthlyRate', 'DailyRate', 'HourlyRate',
                              'Age', #'Education', #'EducationField', 
                              'EnvironmentSatisfaction','JobInvolvement', 'JobSatisfaction', 
                              'RelationshipSatisfaction', 'WorkLifeBalance',
                              'TotalWorkingYears','YearsAtCompany'))]
eda=fp
attach(eda)
```
<br>

####Attrition by Category
<br>
Frito-Lay's combined voluntary turnover for the three departments was 16%, with Sales having the highest percentage at 22%.  

```{r}
prop_eda <- eda %>% dplyr::select(Attrition) %>% group_by(Attrition) %>% summarize(n=n()) %>%
  mutate(pct=round(prop.table(n), 2))

kable(prop_eda)%>%
  kable_styling(full_width = F)
```
As we conducted the exploratory data analysis there were some patterns that began to emerge.
<br>

Attrition by Exemption Status - Non Exempt Employees are leaving at a higher rate than Exempt employees.  The Sales department has higher turnover than HR and R&D.  Single employees are quicker to resign than their married or divorced counterparts.

```{r}
#Attrition by Exemption Status 
par(mfrow=c(2,2))
cross<-table(Attrition, OverTime)
barplot(prop.table(cross,2)*100,
        xlab="Overtime Eligible = 1", ylab="Percentage", main="% Attrition by Exemption",
        beside=T, col=c ("palevioletred3", "skyblue4"))

cross<-table(Attrition, Department)
barplot(prop.table(cross,2)*100,
        ylab="Percentage", main="% Attrition by Department",
        beside=T, cex.names=0.5, col=c ("palevioletred3", "skyblue4"),
        legend=rownames(cross), args.legend = list (x="topright"))

cross<-table(Attrition, MaritalStatus)
barplot(prop.table(cross,2)*100,
        ylab="Percentage", main="% Attrition by Marital Status",
        beside=T, col=c ("palevioletred3", "skyblue4"))

```
<br>
This is an alluvial plot which visualizes categorical data as flows.  It traces all possible pathways of employees who left the company through these variables.
<br>

If we look at this first chart, we can see by the width of the blue lines that employees who left the company tend to be non-exempt, working in Sales and R&D, who are primarily single.
<br>

Conversely, by the width of the grey line, those that didn't leave the company are exempt and primarily working in R&D and, while cover all marital statuses, the majority are married.  The height of the variable boxes, denote population.  For example, R&D has the largest headcount among the three departments.

```{r}
#https://www.kaggle.com/hiteshp/head-start-for-data-scientist/log
#https://cran.r-project.org/web/packages/alluvial/vignettes/alluvial.html

#ALLUVIAL - ATTRITION, OVERTIME, DEPARTMENT, MARTIAL STATUS
par(mfrow=c(1,1))
tbl_summary <- eda %>%
  group_by(Attrition, OverTime, Department, MaritalStatus) %>%
  summarise(N = n()) %>% 
  ungroup 

alluvial(tbl_summary[, c(1:4)],
         freq=tbl_summary$N, border=NA,
         col=ifelse(tbl_summary$Attrition == "Yes", "blue", "gray"),
         cex=0.65,
         ordering = list(
           order(tbl_summary$Attrition, tbl_summary$Department=="Sales"),
           order(tbl_summary$OverTime, tbl_summary$Department=="Sales"),
           NULL, NULL))

```
<br>

Attrition by Age Category, Job Level, and Job Role
```{r}
par(mfrow=c(3,1))
cross<-table(Attrition, AgeCat)
barplot(prop.table(cross,2)*100,
        ylab="Percentage", main="% Attrition by Age category",
        beside=T, col=c ("palevioletred3", "skyblue4"))

cross<-table(Attrition, JobLevel)
barplot(prop.table(cross,2)*100,
        ylab="Percentage", main="% Attrition by Job Level",
        beside=T, col=c ("palevioletred3", "skyblue4"))

par(mfrow=c(1,1))
cross<-table(Attrition, JobRole)
barplot(prop.table(cross,2)*100,
        ylab="Percentage",main="% Attrition by Job Role",
        beside=T,
        cex.names=0.3,
        col=c ("palevioletred3", "skyblue4"))
```

Here we see the flow through job level, age category and role.  We see that the job level with the largest amount of attrition is level 1 (entry level positions) who are less than 35 years of age in the position of sales representative, sales executive, research scientists and lab techs.
```{r}
tbl_summary <- eda %>%
  group_by(Attrition, JobLevel, AgeCat, JobRole) %>%
  summarise(N = n()) %>% 
  ungroup 

alluvial(tbl_summary[, c(1:4)],
         freq=tbl_summary$N, border=NA,
         col=ifelse(tbl_summary$Attrition == "Yes", "blue", "gray"),
         cex=0.65,
         ordering = list(
           order(tbl_summary$Attrition, tbl_summary$AgeCat=="<25"),
           order(tbl_summary$JobLevel, tbl_summary$AgeCat=="<25"),
           NULL, NULL))
```
<br>

Of concern in the charts below are those that are leaving within the first three years of employment.  We also see a larger frequency of those with a technical background leaving at a higher rate. Since Sales roles involve heavy travel, it is not surprising to see that frequent monthly travel has the highest attrition rate.  Also, as long term incetives are utilized to retain higher level employees, we expected to see this since it is the lower level employees who are leaving at a higher rate. 
```{r}
par(mfrow=c(2,1))
ServiceCat <- factor(ServiceCat, levels=c("0-1", "1-3","3-5","5-8", "8-10","10+" ))
cross<-table(Attrition, ServiceCat)
barplot(prop.table(cross,2)*100,
        ylab="Percentage", main="% Attrition by Co Service Category",
        beside=T, col=c ("palevioletred3", "skyblue4"))

cross<-table(Attrition, EducationField)
barplot(prop.table(cross,2)*100,
        ylab="Percentage", main="% Attrition by Education Field",
        beside=T, cex.names=0.5, col=c ("palevioletred3", "skyblue4"))

cross<-table(Attrition, BusinessTravel)
barplot(prop.table(cross,2)*100,
        ylab="Percentage", main="% Attrition by Amount of Monthly BusinessTravel",
        beside=T, col=c ("palevioletred3", "skyblue4"))

cross<-table(Attrition, StockOptionLevel)
barplot(prop.table(cross,2)*100,
        ylab="Percentage", main="% Attrition by Stock Option Level",
        beside=T, col=c ("palevioletred3", "skyblue4"))

```


We also wanted to get a feel based on service category.  Here we see the largest group is in the 1-3 year service categogry, in the Sales and R&D departments.  Similar to the earlier chart, we see the same positional flow, but with better clarity.   
```{r}
tbl_summary <- eda %>%
  group_by(Attrition, ServiceCat, Department, JobRole) %>%
  summarise(N = n()) %>% 
  ungroup 

alluvial(tbl_summary[, c(1:4)],
         freq=tbl_summary$N, border=NA,
         col=ifelse(tbl_summary$Attrition == "Yes", "blue", "gray"),
         cex=0.65,
         ordering = list(
           order(tbl_summary$Attrition, tbl_summary$Department=="Sales"),
           order(tbl_summary$ServiceCat, tbl_summary$Department=="Sales"),
           NULL,NULL))
```

In the graphs below, we do not see noticable differences among the groups.
```{r}

par(mfrow=c(1,3))
cross<-table(Attrition, Gender)
barplot(prop.table(cross,2)*100,
        ylab="Percentage", main="% Attrition by Gender",
        beside=T, col=c ("palevioletred3", "skyblue4"))

cross<-table(Attrition, OtherCoExp)
barplot(prop.table(cross,2)*100,
        xlab="Other Company Experience = 1", ylab="Percentage", main="% Attrition by Other Company Experience",
        beside=T, col=c ("palevioletred3", "skyblue4"))

cross<-table(Attrition, PerformanceRating)
barplot(prop.table(cross,2)*100,
        ylab="Percentage", main="% Attrition by Performance Rating",
        beside=T, col=c ("palevioletred3", "skyblue4"))

```

In terms of education level, it doesn't seem too varied.
```{r}
par(mfrow=c(1,1))
cross<-table(Attrition, Education)
barplot(prop.table(cross,2)*100,
        ylab="Percentage", main="% Attrition by Education Level",
        beside=T, col=c ("palevioletred3", "skyblue4"))
```

####EMPLOYEE SATISFACTION

Attrition by age category with average satisfaction rating
<br>

Interesting here is the less than 25 years of age group, satisfation scores were not that different for those who left vs. those who stayed.  Same with those over 50.  However, retirements are considered voluntary, so that may be a factor at play with this group.
```{r}
comb.AgeCat <- eda %>% dplyr::select(EESatisfaction, AgeCat, Attrition) %>% 
  group_by(AgeCat, Attrition) %>%
  summarize(avg.env=mean(EESatisfaction))

grf.AgeCat<-ggplot(comb.AgeCat, aes(x=AgeCat, y=avg.env)) + 
  geom_line(aes(group=Attrition), color="grey3", linetype="dashed") + 
  geom_point(aes(color=Attrition), size=3) +  
  theme(plot.title=element_text(hjust=0.5), axis.text.x=element_text(angle = 50, hjust = 1)) +
  labs(title="Working Environment", y="Average Employee Satisfaction", x="Age Category") + 
  scale_color_manual(values=c("palevioletred3", "skyblue4"))
grf.AgeCat
```

Attrition by service cagegory with average satisfaction rating
```{r}
comb.los <- eda %>% dplyr::select(EESatisfaction, ServiceCat, Attrition) %>% 
  group_by(ServiceCat, Attrition) %>%
  summarize(avg.env=mean(EESatisfaction))

grf.los<-ggplot(comb.los, aes(x=ServiceCat, y=avg.env)) + 
  geom_line(aes(group=Attrition), color="grey3", linetype="dashed") + 
  geom_point(aes(color=Attrition), size=3) +  
  theme(plot.title=element_text(hjust=0.5), axis.text.x=element_text(angle = 50, hjust = 1)) +
  labs(title="Working Environment", y="Average Employee Satisfaction", x="Service Category") + 
  scale_color_manual(values=c("palevioletred3", "skyblue4"))
grf.los
```

Attrition by Job Role with average satisfaction rating.  
<br>

Of interest is the Research Director position, which had a decent satisfaction score, but yet still resigned.  This would be a good area to dive deeper into the underlying cause.
```{r}

comb.jobrole <- eda %>% dplyr::select(EESatisfaction, JobRole, Attrition) %>% 
  group_by(JobRole, Attrition) %>%
  summarize(avg.env=mean(EESatisfaction))

grf.JobRole<-ggplot(comb.jobrole, aes(x=JobRole, y=avg.env)) + 
  geom_line(aes(group=Attrition), color="grey3", linetype="dashed") + 
  geom_point(aes(color=Attrition), size=3) +  
  theme(plot.title=element_text(hjust=0.5), axis.text.x=element_text(angle = 75, hjust = 1)) +
  labs(title="Working Environment", y="Average Employee Satisfaction", x="Job Role") + 
  scale_color_manual(values=c("palevioletred3", "skyblue4"))
grf.JobRole

detach(eda)
```


###Identification of top three variables predictcing Turnover
```{r}
fp2=fp
fp2$StockOptionLevel <- factor(fp2$StockOptionLevel)
fp2$OverTime <- factor(fp2$OverTime)
fp2$OtherCoExp <- factor(fp2$OtherCoExp)
fp2$PromoLast3 <- factor(fp2$PromoLast3)

#randomforest method
set.seed(112)

# Random Forest relative importance of variables as predictors
rffit <- randomForest(Attrition ~.,data=fp2, ntree=2000, keep.forest=FALSE, importance=TRUE)
feat_imp_df <- importance(rffit) %>% 
  data.frame() %>% 
  mutate(feature = row.names(.)) 

# plot dataframe
ggplot(feat_imp_df, aes(x = reorder(feature, MeanDecreaseGini), y = MeanDecreaseGini)) +
  geom_bar(stat='identity', fill = 'steelblue')+
  coord_flip() +
  theme_classic() +
  scale_fill_brewer(palette="Set3")+
  labs(x= "Feature", y = "Importance",title = "Variable Importance")
  
```

We dove deeper into the top three variables.
<br>

The top six Education Level / Field of Study with the highest turnover are:
<br>

* Bachelor's - Life Sciences    16%
* Some College - Life Sciences  10%
* Bachelor's - Medical          9%
* Master's - Life sciences      9%
* Some College - Medical        7%
* Master's - Medical            7%
<br>

Life Sciences and Medical backgrounds are typical fields of study for R&D positions and as we saw earlier, there is a high attrition rate among Lab Techs and Research Scientists.
<br>
<br>
Nothing suprising in the Employee Satisfaction chart below, we would expect employees with lower satisfication scores to seek opportunities elsewhere.
```{r}
eda$esat <- cut(eda$EESatisfaction, c(-Inf, 1.5, 2, 2.5, 3, 3.5, 4, Inf))
levels(eda$esat) <- c("<1.5", "1.5-2.0", "2.0-2.5", "2.5-3.0","3.0-3.5", "3.5-4.0", "4.0+")

cross<-table(eda$Attrition, eda$esat)
barplot(prop.table(cross,2)*100,
        xlab="Employee Satisfaction", ylab="Percentage", main="% Attrition",
        beside=T, col=c ("palevioletred3", "skyblue4"),
        legend=rownames(cross), args.legend = list (x="topright"))
```

We looked at attrition by monthly income group and average satisfaction rating
<br>

Employees who resigned in the 5-10k income bracket have extremely low average satisfaction scores.
```{r}
eda$MIGroup <- cut(eda$MonthlyIncome, c(-Inf, 5000, 10000, 15000, 20000, Inf))
levels(eda$MIGroup) <- c("<5k", "5-10k", "10-15k", "15-20k", "20k+")

comb.MIG <- eda %>% dplyr::select(EESatisfaction, MIGroup, Attrition) %>% 
  group_by(MIGroup, Attrition) %>%
  summarize(avg.env=mean(EESatisfaction))

grf.MIG<-ggplot(comb.MIG, aes(x=MIGroup, y=avg.env)) + 
  geom_line(aes(group=Attrition), color="grey3", linetype="dashed") + 
  geom_point(aes(color=Attrition), size=3) +  
  theme(plot.title=element_text(hjust=0.5), axis.text.x=element_text(angle = 50, hjust = 1)) +
  labs(title="Working Environment", y="Average Employee Satisfaction", x="Monthly Income Group") + 
  scale_color_manual(values=c("palevioletred3", "skyblue4"))
grf.MIG


```

In the chart below, we see that those earning less than $5,000 per month are leaving the organization at a higher rate.  Again, this supports our earlier findings of non exempt, lower level attrition.

```{r}
cross<-table(eda$Attrition, eda$MIGroup)
barplot(prop.table(cross,2)*100,
        xlab="Monthly Income Group", ylab="Percentage", main="% Attrition",
        beside=T, col=c ("palevioletred3", "skyblue4"),
        legend=rownames(cross), args.legend = list (x="topright"))
```

###Attrition Prediction
<br>

####CORRELATION 
<br>
Job Level + Monthly Income has a correlation of 1
<br>
Years in Current role + Years with Current Manager = 0.7
<br>
Years since last promotion + Years in Current Role = 0.8
<br>
Variables are being left in for now and we will revisit during classification / modeling.

```{r}
#Remove individual fields that make up combined Educ_Field (were needed for graphing)
fp = fp[ , !(names(fp) %in% c('Education', 'EducationField'))]
```

```{r}
nums <- select_if(fp, is.numeric)
corr <- round(cor(nums), 1)
ggcorrplot(corr, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 2, 
           method="square", 
           colors = c("tomato2", "white", "#01A9DB"), 
           title="Correlation Matrix", 
           ggtheme=theme_minimal())
```



###Classification/Prediction
<br>

####KNN
```{r}

fpD=fp
fpD$StockOptionLevel <- factor(fpD$StockOptionLevel)
fpD$OverTime <- factor(fpD$OverTime)
fpD$OtherCoExp <- factor(fpD$OtherCoExp)
fpD$PromoLast3 <- factor(fpD$PromoLast3)

fpD <- fastDummies::dummy_cols(fpD, remove_first_dummy = TRUE) 
# Deleting the columns for which dummies are created
fpD = subset(fpD, select = -c(Attrition, AgeCat, Educ_Field, BusinessTravel, 
                                JobRole, Department, StockOptionLevel, OverTime, Gender, 
                                MaritalStatus, OtherCoExp, ServiceCat, PromoLast3))

fpD<-fpD[c(13, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73)]

fpD$Attrition_Yes = as.factor(fpD$Attrition_Yes)

```

####Create Training and Test File and check proportions
```{r}

set.seed(111)
data_part<-createDataPartition(fpD$Attrition_Yes,p=0.7,list=FALSE,times=1)
train.K<-fpD[data_part,]
test.K<-fpD[-data_part,]   

prop_fpD <- fpD %>% dplyr::select(Attrition_Yes) %>% group_by(Attrition_Yes) %>% summarize(n=n()) %>%
  mutate(pct=round(prop.table(n), 2))

prop_train.K <- train.K %>% dplyr::select(Attrition_Yes) %>% group_by(Attrition_Yes) %>% summarize(n=n()) %>%
  mutate(pct=round(prop.table(n), 2))

prop_test.K <- test.K %>% dplyr::select(Attrition_Yes) %>% group_by(Attrition_Yes) %>% summarize(n=n()) %>%
  mutate(pct=round(prop.table(n), 2))

prop_fpD
prop_train.K
prop_test.K

```

Run the KNN with 3 nearest neighbors classification.
```{r}
results=class::knn(train.K[,c(2:73)],test.K[,c(2:73)],train.K$Attrition_Yes,k=3)
test.K$Attrition_YesPred=results
confusionMatrix(table(test.K$Attrition_Yes,test.K$Attrition_YesPred))
```

Results weren't the best, we will center and scale the data and rerun to see if it improves.
<br>
```{r}
set.seed(111)
ctrl <- trainControl(method="cv",repeats = 3) 
knnFit <- train(Attrition_Yes ~ ., data = train.K, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)
knnFit
plot(knnFit)
```

There were near zero variance warnings that need to be checked.
```{r}

nzv <- nearZeroVar(fpD, saveMetrics= TRUE)
nzv[nzv$nzv,][2:73,]
```



Remove near zero variance variables
```{r}
filteredfpD = fpD[ , !(names(fpD) %in% c('Educ_Field_1_Technical Degree', 'Educ_Field_5_Medical', 'Educ_Field_4_Technical Degree', 'Educ_Field_3_Other',  'Educ_Field_2_Marketing', 'Educ_Field_1_Marketing', 'Educ_Field_4_Other', 'Educ_Field_3_Marketing', 'Educ_Field_3_Technical Degree', 'Educ_Field_5_Marketing', 
'Educ_Field_2_Technical Degree', 'Educ_Field_2_Other', 'Educ_Field_1_Life Sciences', 'Educ_Field_1_Medical','Educ_Field_4_Human Resources', 'Educ_Field_3_Human Resources', 'Educ_Field_5_Life Sciences', 'Educ_Field_5_Human Resources', 'Educ_Field_1_Other', 'Educ_Field_5_Technical Degree', 'Educ_Field_1_Human Resources',
'Educ_Field_2_Human Resources', 'JobRole_Human Resources', 'Department_Human Resources', 'ServiceCat_0-1'))]

filteredfpD$Attrition_Yes = as.factor(filteredfpD$Attrition_Yes)
```

Create the training and test datasets with the revised data.
```{r}
set.seed(111)
data_part<-createDataPartition(filteredfpD$Attrition_Yes,p=0.7,list=FALSE,times=1)
train.KF<-filteredfpD[data_part,]
test.KF<-filteredfpD[-data_part,]  
```

Training and train control
```{r}
ctrl2 <- trainControl(method="cv") 
knnFit2 <- train(Attrition_Yes ~ ., data = train.KF, method = "knn", trControl = ctrl2, preProcess = c("center","scale"), tuneLength = 20)

knnFit2

plot(knnFit2)
```
Prediction confusion matrix of model.
```{r}
knnPredict2 <- predict(knnFit2,newdata = test.KF)

confusionMatrix(knnPredict2, test.KF$Attrition_Yes)
```
This model was much worse than the original KNN model.
<br>


####LOGISTIC CLASSIFICATION

As we discoverd during the correlation check:
<br>
Job Level + Monthly Income has a correlation of 1. The full model was run with both, and either/or and the best result was with removing Job Level.
<br>

Years in Current role + Years with Current Manager = 0.7. The full model was run with both, and either/or and the best result was with Years with Current Manager.
```{r}
fpL = fp2[ , !(names(fp) %in% c('JobLevel','YearsWithCurrManager'))]
```

Create training and test database
```{r}
set.seed(112) #caret
data_part<-createDataPartition(fpL$Attrition,p=0.7,list=FALSE,times=1)
trainL<-fpL[data_part,]
testL<-fpL[-data_part,]  
```


FULL MODEL incorporating all predictors:
```{r}
#https://stats.idre.ucla.edu/r/dae/logit-regression/
#http://www.sthda.com/english/articles/36-classification-methods-essentials/150-stepwise-logistic-regression-essentials-in-r/


# Fit the model
full.model <- glm(Attrition ~., data = trainL, family = binomial)

# Make predictions
probabilities <- full.model %>% predict(testL, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "Yes", "No")
predicted.classes <- factor(predicted.classes)

# Model accuracy
observed.classes <- testL$Attrition
mean(predicted.classes == observed.classes)
caret::confusionMatrix(predicted.classes,testL$Attrition)   

```


DEFAULT STEP (BACKWARD)
```{r}
# Fit the model
back.model <- full.model %>% stepAIC(trace = FALSE) #default=backward

# Make predictions
probabilitiesb<- predict(back.model, testL, type = "response")
predicted.classesb <- ifelse(probabilitiesb > 0.5, "Yes", "No")
predicted.classesb <- factor(predicted.classesb)

# Prediction accuracy
observed.classesb <- testL$Attrition
mean(predicted.classesb == observed.classesb)
caret::confusionMatrix(predicted.classesb,testL$Attrition)

```

STEPWISE
```{r}
#Fit the model
step.model <- full.model %>% stepAIC(direction = "both", trace = FALSE)

# Make predictions
probabilitiesS<- predict(step.model, testL, type = "response")
predicted.classesS <- ifelse(probabilitiesS > 0.5, "Yes", "No")
predicted.classesS <- factor(predicted.classesS)

# Prediction accuracy
observed.classesS <- testL$Attrition
mean(predicted.classesS == observed.classesS)
caret::confusionMatrix(predicted.classesS,testL$Attrition)

```

FORWARD
```{r}
#Fit the model
forw.model <- full.model %>% stepAIC(direction = "forward", trace = FALSE)

# Make predictions
probabilitiesf<- predict(forw.model, testL, type = "response")
predicted.classesf <- ifelse(probabilitiesf > 0.5, "Yes", "No")
predicted.classesf <- factor(predicted.classesf)

# Prediction accuracy
observed.classesf <- testL$Attrition
mean(predicted.classesf == observed.classesf)
caret::confusionMatrix(predicted.classesf,testL$Attrition)

```
Of all the logistic models, backward and stepwise had the same, best results with Sensitivity at 94% and Specificity at 57%.  However, since our goal is a minimum of 60 on each measure, we will move on to the random forest method.

####RANDOM FOREST

Training and test files
```{r}
rf=fp
rf$StockOptionLevel <- factor(rf$StockOptionLevel)
rf$OverTime <- factor(rf$OverTime)
rf$OtherCoExp <- factor(rf$OtherCoExp)
rf$PromoLast3 <- factor(rf$PromoLast3)

set.seed(112) #caret
data_part<-createDataPartition(rf$Attrition,p=0.7,list=FALSE,times=1)
trainRF<-rf[data_part,]
testRF<-rf[-data_part,] 
```

Building the model and predicting on test data.
```{r}
#Building the model
modelRF <- randomForest(Attrition~.,trainRF, importance=TRUE,ntree=1000)

#Predict to test data
predRF <- predict(modelRF, newdata = testRF)
confusionMatrix(testRF$Attrition, predRF)
```

```{r}
plotRF<- plot.roc(as.numeric(testRF$Attrition), 
                       as.numeric(predRF),lwd=2, type="b",print.auc=TRUE,col ="blue")
```

As seen in the confusion matrices, Random Forest had the best accuracy and sensitivity out of all the models, both >60.  We will use this method to predict the attrition classification.

####Attrition classification prediction using random forest.
<br>

Read in and format the validation file
```{r}
ap<-read.csv("CS2_Validation_Comb.csv", header=T,na.strings=c(""))

ap = ap[ , !(names(ap) %in% c('File', 'Attrition', 'Over18', 'StandardHours', 'EmployeeCount',  'EmployeeNumber','Rand',
 'MonthlyRate', 'DailyRate', 'HourlyRate','Age', 'Education', 'EducationField', 'EnvironmentSatisfaction','JobInvolvement', 'JobSatisfaction',  'RelationshipSatisfaction', 'WorkLifeBalance','TotalWorkingYears','YearsAtCompany'))]

ap$Attrition<-""
trainRF$ID<-""
```

Solution to "New factor levels not present in the training data"
<br>
<https://stackoverflow.com/questions/17059432/random-forest-package-in-r-shows-error-during-prediction-if-there-are-new-fact>
```{r}
#convert factors to character in both training set and prediction set
ap$ID <- as.character(ap$ID)
ap$AgeCat <- as.character(ap$AgeCat)
ap$Educ_Field <- as.character(ap$Educ_Field)
ap$BusinessTravel <- as.character(ap$BusinessTravel)
ap$JobRole <- as.character(ap$JobRole)
ap$JobLevel <- as.character(ap$JobLevel)
ap$Department <- as.character(ap$Department)
ap$StockOptionLevel  <- as.character(ap$StockOptionLevel)
ap$OverTime <- as.character(ap$OverTime)
ap$Gender <- as.character(ap$Gender)
ap$MaritalStatus <- as.character(ap$MaritalStatus)
ap$OtherCoExp <- as.character(ap$OtherCoExp)
ap$ServiceCat <- as.character(ap$ServiceCat)
ap$PromoLast3 <- as.character(ap$PromoLast3)
ap$PerformanceRating <- as.character(ap$PerformanceRating)

trainRF$Attrition <- as.character(trainRF$Attrition)
trainRF$AgeCat <- as.character(trainRF$AgeCat)
trainRF$Educ_Field <- as.character(trainRF$Educ_Field)
trainRF$BusinessTravel <- as.character(trainRF$BusinessTravel)
trainRF$JobRole <- as.character(trainRF$JobRole)
trainRF$JobLevel <- as.character(trainRF$JobLevel)
trainRF$Department <- as.character(trainRF$Department)
trainRF$StockOptionLevel  <- as.character(trainRF$StockOptionLevel)
trainRF$OverTime <- as.character(trainRF$OverTime)
trainRF$Gender <- as.character(trainRF$Gender)
trainRF$MaritalStatus <- as.character(trainRF$MaritalStatus)
trainRF$OtherCoExp <- as.character(trainRF$OtherCoExp)
trainRF$ServiceCat <- as.character(trainRF$ServiceCat)
trainRF$PromoLast3 <- as.character(trainRF$PromoLast3)
trainRF$PerformanceRating <- as.character(trainRF$PerformanceRating)


#add testing file flag to both files
ap$isTest <- rep(1,nrow(ap))
trainRF$isTest <- rep(0,nrow(trainRF))

#combine files
fullSet <- rbind(ap,trainRF)

#convert characters back to factors
fullSet$Attrition <- as.factor(fullSet$Attrition)
fullSet$AgeCat <- as.factor(fullSet$AgeCat)
fullSet$Educ_Field <- as.factor(fullSet$Educ_Field)
fullSet$BusinessTravel <- as.factor(fullSet$BusinessTravel)
fullSet$JobRole <- as.factor(fullSet$JobRole)
fullSet$JobLevel <- as.factor(fullSet$JobLevel)
fullSet$Department <- as.factor(fullSet$Department)
fullSet$StockOptionLevel  <- as.factor(fullSet$StockOptionLevel)
fullSet$OverTime <- as.factor(fullSet$OverTime)
fullSet$Gender <- as.factor(fullSet$Gender)
fullSet$MaritalStatus <- as.factor(fullSet$MaritalStatus)
fullSet$OtherCoExp <- as.factor(fullSet$OtherCoExp)
fullSet$ServiceCat <- as.factor(fullSet$ServiceCat)
fullSet$PromoLast3 <- as.factor(fullSet$PromoLast3)
fullSet$PerformanceRating <- as.factor(fullSet$PerformanceRating)

#split files back apart/clean up
test.new <- fullSet[fullSet$isTest==1,]
train.new <- fullSet[fullSet$isTest==0,]

test.new= test.new[ , !(names(ap) %in% c('isTest'))]
train.new = train.new [ , !(names(ap) %in% c('isTest','ID'))]

train.new$Attrition <- factor(train.new$Attrition)
```

Build the model
```{r}
#Building the model
modelRF2 <- randomForest(Attrition~.,train.new, importance=TRUE,ntree=1000)
```

Predict to validation file
```{r}
test.new$pred<- predict(modelRF2, newdata = test.new)
#Export the file
write.csv(test.new,'Case2PredictionsEliasenAttrition.csv')
```

```

###Salary Prediction
<br>
<br>

Bring in original files from the first part, clean up and combine for a more robust dataset for model building.

```{r}
s1 <- read.csv("CS2_data_comb.csv", header=T,na.strings=c(""))
s2<-read.csv("CS2_Validation_Comb.csv", header=T,na.strings=c(""))

s1 = s1[ , !(names(s1) %in% c('ID', 'Attrition', 'Over18', 'StandardHours', 'EmployeeCount',  'EmployeeNumber','Rand','MonthlyRate', 'DailyRate', 'HourlyRate', 'Age', 'Education', 'EducationField', 'EnvironmentSatisfaction','JobInvolvement', 'JobSatisfaction',  'RelationshipSatisfaction','WorkLifeBalance','TotalWorkingYears','YearsAtCompany'))]

s2 = s2[ , !(names(s2) %in% c('ID', 'Over18', 'StandardHours', 'EmployeeCount',  'EmployeeNumber','Rand', 'MonthlyRate', 'DailyRate', 'HourlyRate',  'Age', 'Education', 'EducationField',  'EnvironmentSatisfaction','JobInvolvement', 'JobSatisfaction', 
  'RelationshipSatisfaction', 'WorkLifeBalance', 'TotalWorkingYears','YearsAtCompany'))]

df <- rbind(s1,s2)

df$StockOptionLevel <- factor(df$StockOptionLevel)
df$OverTime <- factor(df$OverTime)
df$OtherCoExp <- factor(df$OtherCoExp)
df$PromoLast3 <- factor(df$PromoLast3)
```

Histogram of Monthly Income
```{r}
histogram(df$MonthlyIncome)

```

Monthly Income has a right skewed distribution, which we need to correct.  We will take the log and see if that helps.
```{r}
df$LMI<- log(df$MonthlyIncome)
histogram(df$LMI)
```

After the log coversion, the distribution of monthly income is more normal.
<br>

####Correlation check.  <br>
<br>

Job Level and log(MonthlyIncome) have a correlation of .92.  Since each job level has a range of pay associated with it, this is not an issue.  In this case, it is a good thing and means that the company is managing pay appropriately within and between each of the job levels.
```{r}
nums <- select_if(df, is.numeric)
nums = nums[ , !(names(nums) %in% c('MonthlyIncome'))]

# comparison against the log(monthlysalary) column
corr.df <- cbind(nums, df['LMI'])
correlations <- cor(corr.df)

# strong correlations with log(MonthlyIncome)
corr.LMI <- as.matrix(sort(correlations[,'LMI'], decreasing = TRUE))
corr.idx <- names(which(apply(corr.LMI, 1, function(x) (x > 0.7 | x < -0.7))))
corrplot(as.matrix(correlations[corr.idx,corr.idx]), type = 'upper', method='color', 
         addCoef.col = 'white', tl.cex = .7,cl.cex = .7, number.cex=.7)
```

####MODELING

Create training and testing datasets
```{r}
set.seed(11) 
data_part<-createDataPartition(df$LMI,p=0.7,list=FALSE,times=1)
train.ls<-df[data_part,]
test.ls<-df[-data_part,]
```

ML Regression
```{r}
#Model
linreg <- lm(LMI~.-MonthlyIncome, data = train.ls)
summary(linreg)
```

Prediction on test set
```{r warning=FALSE}
pred1 <- predict(linreg,test.ls,type = "response")
residuals <- test.ls$LMI - pred1
linreg_pred <- data.frame("Predicted" = pred1, "Actual" = test.ls$LMI, "Residual" = residuals)
plot(pred1, test.ls$LMI, main = "Linear Regression - Predicted vs. Actual log Monthly Income") 
abline(0,1)
```

```{r}
accuracy(pred1, test.ls$LMI)

```

####Random Forest Model
```{r}

RFLS <- randomForest(LMI~.-MonthlyIncome, data = train.ls, 
                   importance =TRUE,ntree=1000,nodesize=7, na.action=na.roughfix)
```


Check variable importance so we can compare against linear
```{r}
# variable importance
options(repr.plot.width=9, repr.plot.height=6)
varImpPlot(RFLS, type=1)
```

Prediction
```{r}

rf.pred <- predict(RFLS, newdata=test.ls )

plot(rf.pred, test.ls$LMI, main = "Random Forest Predicted vs. Actual log Monthly Income") 
abline(0,1)
```

Check accuracy
```{r}
accuracy(rf.pred, test.ls$LMI)
```

Both models did well and had an RSME score below 0.3.  We will move forward with the logistic model for the prediction of salaries.   

Bring in prediction file
```{r}
mp<-read.csv("CS2_MonthlyIncome_Comb.csv", header=T,na.strings=c(""))
mp = mp[ , !(names(mp) %in% c('Attrition', 'Over18', 'StandardHours', 'EmployeeCount',  'EmployeeNumber','Rand', 'MonthlyRate', 'DailyRate', 'HourlyRate', 'Age', 'Education', 'EducationField',  'EnvironmentSatisfaction','JobInvolvement', 'JobSatisfaction',  'RelationshipSatisfaction', 'WorkLifeBalance','TotalWorkingYears','YearsAtCompany'))]

mp$StockOptionLevel <- factor(mp$StockOptionLevel)
mp$OverTime <- factor(mp$OverTime)
mp$OtherCoExp <- factor(mp$OtherCoExp)
mp$PromoLast3 <- factor(mp$PromoLast3)

mp$MonthlyIncome<-0
```

Create the prediction file
```{r}
mp$logMIPred<-predict(linreg, newdata=mp)
mp$MIPred<-exp(mp$logMIPred)
#Export the file
write.csv(mp,'Case2PredictionsEliasenSalaries.csv')
```








